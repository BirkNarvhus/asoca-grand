{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import monai.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.networks.nets import UNet\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from monai.transforms import Compose, LoadImageD, CropForegroundD, ToTensorD, RandSpatialCropD, CenterSpatialCropD, EnsureChannelFirstd, EnsureTyped, NormalizeIntensityd, RandScaleIntensityd, \\\n",
    "    RandShiftIntensityd, LoadImaged\n",
    "from monai.metrics import HausdorffDistanceMetric, DiceMetric, MeanIoU\n",
    "from monai.losses import DiceFocalLoss\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml \n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader\n",
    "except ImportError:\n",
    "    from yaml import Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eb4849c299496",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "config_dict = {}\n",
    "try:\n",
    "    with open(\"configs.yaml\", 'r') as stream:\n",
    "        config_dict = yaml.load(stream, Loader)\n",
    "except FileNotFoundError:\n",
    "    print(\"Config file not found.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf87d3e90d5344",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Meter:\n",
    "    '''factory for storing and updating iou and dice scores.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.haus_dorf = HausdorffDistanceMetric(percentile=0.95, reduction='mean', include_background=False,\n",
    "                                                 get_not_nans=False)\n",
    "        self.dice = DiceMetric(include_background=False, reduction='mean', get_not_nans=False)\n",
    "        self.iou = MeanIoU(include_background=False, reduction='mean', get_not_nans=False)\n",
    "\n",
    "    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes: logits from output model and targets,\n",
    "        calculates dice and iou scores, and stores them in lists.\n",
    "        \"\"\"\n",
    "        self.haus_dorf(logits, targets)\n",
    "        self.dice(logits, targets)\n",
    "        self.iou(logits, targets)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"\n",
    "        Returns: the average of the accumulated dice and iou scores.\n",
    "        \"\"\"\n",
    "        dice = self.dice.aggregate().item()\n",
    "        iou = self.iou.aggregate().item()\n",
    "        hausdorff = self.haus_dorf.aggregate().item()\n",
    "        return dice, iou, hausdorff\n",
    "\n",
    "    def reset(self):\n",
    "        self.dice.reset()\n",
    "        self.iou.reset()\n",
    "        self.haus_dorf.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945b9f605124024",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 criterion: nn.Module,\n",
    "                 train_loader: DataLoader,\n",
    "                 test_loader: DataLoader,\n",
    "                 epochs: int = 100,\n",
    "                 device: str = 'cuda',\n",
    "                 plot=False,\n",
    "                 log_dir: str = 'logs',\n",
    "                 checkpoint_dir: str = 'checkpoints',\n",
    "                 output_dir: str = 'outputs',\n",
    "                 checkpoint_interval: int = 10,\n",
    "                 lr_scheduler=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.plot = plot\n",
    "\n",
    "        self.losses = {'train': [], 'test': []}\n",
    "        self.dice_scores = {'train': [], 'test': []}\n",
    "        self.iou_scores = {'train': [], 'test': []}\n",
    "        self.hausdorff_scores = {'train': [], 'test': []}\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "\n",
    "        if not os.path.exists(self.checkpoint_dir):\n",
    "            os.makedirs(self.checkpoint_dir)\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        self.best_test_loss = np.inf\n",
    "\n",
    "        self.meter = Meter()\n",
    "\n",
    "    def loss_and_logits(self, images: torch.Tensor, masks: torch.Tensor):\n",
    "        images = images.to(self.device)\n",
    "        masks = masks.to(self.device)\n",
    "\n",
    "        logits = self.model(images)\n",
    "        loss = self.criterion(logits, masks)\n",
    "        return loss, logits\n",
    "\n",
    "    def next_epoch(self, epoch, test=False):\n",
    "        self.model.train() if not test else self.model.eval()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        if not test:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        for i, (images, masks) in enumerate(self.train_loader if not test else self.test_loader):\n",
    "            loss, logits = self.loss_and_logits(images, masks)\n",
    "\n",
    "            if not test:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            self.meter.update(logits.detach().cpu(), masks.detach().cpu())\n",
    "\n",
    "        epoch_loss = running_loss / len(self.train_loader if not test else self.test_loader)\n",
    "        dice, iou, hausdorff = self.meter.get_metrics()\n",
    "        self.meter.reset()\n",
    "\n",
    "        self.losses['train' if not test else 'test'].append(epoch_loss)\n",
    "        self.dice_scores['train' if not test else 'test'].append(dice)\n",
    "        self.iou_scores['train' if not test else 'test'].append(iou)\n",
    "        self.hausdorff_scores['train' if not test else 'test'].append(hausdorff)\n",
    "\n",
    "        return epoch_loss, (dice, iou, hausdorff)\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            self.next_epoch(epoch, test=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                test_loss, metrics = self.next_epoch(epoch, test=True)\n",
    "                self.lr_scheduler.step(test_loss)\n",
    "\n",
    "            if self.plot:\n",
    "                self.plot_metrics()\n",
    "\n",
    "            if test_loss < self.best_test_loss:\n",
    "                print(\n",
    "                    f\"Saving best model with test loss: {test_loss:.4f} and metrics: dice - {metrics[0]:.4f} iou - {metrics[1]:.4f} hassdorf - {metrics[2]:.4f} at epoch: {epoch + 1}\")\n",
    "                self.best_test_loss = test_loss\n",
    "                torch.save(self.model.state_dict(), self.output_dir + \"/\" + 'best_model.pth')\n",
    "\n",
    "            if (epoch + 1) % self.checkpoint_interval == 0:\n",
    "                print(f\"Saving checkpoint at epoch: {epoch + 1}\")\n",
    "                torch.save(self.model.state_dict(), self.checkpoint_dir + \"/\" + f'epoch_{epoch + 1}.pth')\n",
    "\n",
    "        self.save_log()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.losses['train'], label='train')\n",
    "        plt.plot(self.losses['test'], label='test')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.dice_scores['train'], label='train')\n",
    "        plt.plot(self.dice_scores['test'], label='test')\n",
    "        plt.title('Dice')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(self.iou_scores['train'], label='train')\n",
    "        plt.plot(self.iou_scores['test'], label='test')\n",
    "        plt.title('IOU')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(self.hausdorff_scores['train'], label='train')\n",
    "        plt.plot(self.hausdorff_scores['test'], label='test')\n",
    "        plt.title('Hausdorff')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def save_log(self):\n",
    "        torch.save(self.model.state_dict(), self.output_dir + \"/\" + 'last_epoch.pth')\n",
    "\n",
    "        log = pd.DataFrame({\n",
    "            'train_loss': self.losses['train'],\n",
    "            'test_loss': self.losses['test'],\n",
    "            'train_dice': self.dice_scores['train'],\n",
    "            'test_dice': self.dice_scores['test'],\n",
    "            'train_iou': self.iou_scores['train'],\n",
    "            'test_iou': self.iou_scores['test'],\n",
    "            'train_hausdorff': self.hausdorff_scores['train'],\n",
    "            'test_hausdorff': self.hausdorff_scores['test']\n",
    "        })\n",
    "        log.to_csv(self.log_dir + \"/\" + 'log.csv', index=False)\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        print(f\"Loading model from {path}\")\n",
    "        self.model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9fcb99318b9c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_paths(path_array):\n",
    "    if isinstance(path_array, str):\n",
    "        path_array = [path_array]\n",
    "    \n",
    "    allPaths = []\n",
    "    for path in path_array:\n",
    "        allPaths.append(sorted(glob(os.path.join(path, '*.nrrd'))))\n",
    "    return list(np.reshape(allPaths, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57c5be88549caf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "path_to_image = get_paths(config_dict['dataset']['image_path'])\n",
    "path_to_masks = get_paths(config_dict['dataset']['mask_path'])\n",
    "\n",
    "\n",
    "data = [{'image': image, 'mask': mask} for image, mask in zip(path_to_image, path_to_masks)]\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImageD(keys=[\"image\", \"mask\"], reader=\"itkreader\"),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "    EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "    CenterSpatialCropD(keys=[\"image\", \"mask\"], roi_size=[400, 400, 100]),\n",
    "    RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=[256, 256, 80], random_size=False),\n",
    "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "    RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "    ToTensorD(keys=[\"image\", \"mask\"]),\n",
    "])\n",
    "\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "        CropForegroundD(keys=[\"image\", \"mask\"], source_key=\"image\", allow_smaller=False),\n",
    "        CenterSpatialCropD(keys=[\"image\", \"mask\"], roi_size=[256, 256, 80]),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ToTensorD(keys=[\"image\", \"mask\"]),\n",
    "    ]\n",
    ")\n",
    "train_set = monai.data.CacheDataset(data[:int(len(data)*0.8)], transform=train_transforms) if config_dict['dataset']['cache_dataset'] else monai.data.Dataset(data[:int(len(data)*0.8)], transform=train_transforms)\n",
    "test_set = monai.data.CacheDataset(data[int(len(data)*0.8):], transform=val_transform) if config_dict['dataset']['cache_dataset'] else monai.data.Dataset(data[int(len(data)*0.8):], transform=val_transform)\n",
    "\n",
    "train_loader = monai.data.DataLoader(train_set, batch_size=config_dict['trainer']['batch_size'], num_workers=config_dict['trainer']['num_workers'], shuffle=True, collate_fn=monai.data.pad_list_data_collate)\n",
    "test_loader = monai.data.DataLoader(test_set, batch_size=config_dict['trainer']['batch_size'], num_workers=config_dict['trainer']['num_workers'], shuffle=True, collate_fn=monai.data.pad_list_data_collate)\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e91569a79bd72",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims= config_dict['model']['spatial_dims'],\n",
    "    in_channels= config_dict['model']['in_channels'],\n",
    "    out_channels= config_dict['model']['out_channels'],\n",
    "    channels= config_dict['model']['channels'],\n",
    "    strides= config_dict['model']['strides'],\n",
    "    num_res_units= config_dict['model']['num_res_units'],\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), config_dict['optimizer']['params']['lr'])\n",
    "\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, config_dict['optimizer']['scheduler']['params']['mode'], factor=config_dict['optimizer']['scheduler']['params']['factor'], patience=config_dict['optimizer']['scheduler']['params']['patience'])\n",
    "\n",
    "criterion = DiceFocalLoss()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"running on device: \", device)\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, train_loader, test_loader, epochs=config_dict['trainer']['epochs'], plot=config_dict['trainer']['plot'], device=device, log_dir=config_dict['trainer']['log_dir'], checkpoint_dir=config_dict['trainer']['checkpoint_dir'], output_dir=config_dict['trainer']['output_dir'], checkpoint_interval=config_dict['trainer']['checkpoint_interval'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b7417b2855ec7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
