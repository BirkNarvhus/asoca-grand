{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:00:57.400175700Z",
     "start_time": "2024-04-22T23:00:57.397660400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nrrd\n",
    "from IPython.display import Image as show_gif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import pydicom as pdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4830403f7e9cbd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.002851400Z",
     "start_time": "2024-04-22T22:36:37.999824800Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageToGIF:\n",
    "    \"\"\"Create GIF without saving image files.\"\"\"\n",
    "    def __init__(self,\n",
    "                 size=(600, 400), \n",
    "                 xy_text=(80, 10),\n",
    "                 dpi=100, \n",
    "                 cmap='CMRmap'):\n",
    "\n",
    "        self.fig = plt.figure()\n",
    "        self.fig.set_size_inches(size[0] / dpi, size[1] / dpi)\n",
    "        self.xy_text = xy_text\n",
    "        self.cmap = cmap\n",
    "        \n",
    "        self.ax = self.fig.add_axes([0, 0, 1, 1])\n",
    "        self.ax.set_xticks([])\n",
    "        self.ax.set_yticks([])\n",
    "        self.images = []\n",
    " \n",
    "    def add(self, *args, label, with_mask=True):\n",
    "        \n",
    "        image = args[0]\n",
    "        mask = args[-1]\n",
    "        plt.set_cmap(self.cmap)\n",
    "        plt_img = self.ax.imshow(image, animated=True)\n",
    "        if with_mask:\n",
    "            plt_mask = self.ax.imshow(np.ma.masked_where(mask == False, mask),\n",
    "                                      alpha=0.7, animated=True)\n",
    "\n",
    "        plt_text = self.ax.text(*self.xy_text, label, color='red')\n",
    "        to_plot = [plt_img, plt_mask, plt_text] if with_mask else [plt_img, plt_text]\n",
    "        self.images.append(to_plot)\n",
    "        plt.close()\n",
    " \n",
    "    def save(self, filename, fps):\n",
    "        animation = anim.ArtistAnimation(self.fig, self.images)\n",
    "        animation.save(filename, writer='ffmpeg', fps=fps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eccc5ae40fc50bc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.008753600Z",
     "start_time": "2024-04-22T22:36:38.003850200Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_nrrd_file(path: str, \n",
    "                   tensor_shape: tuple ) -> np.ndarray:\n",
    "    if os.path.exists(path):\n",
    "        tensor = nrrd.read(path)[0]                             \n",
    "        tensor = np.flip(tensor, -1)                   # Warning! slice order of images and masks does not match.\n",
    "    else: \n",
    "        tensor = np.zeros(tensor_shape, dtype=np.float32)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def nrrd_to_numpy(id_: str, tensor_shape: tuple):\n",
    "    '''\n",
    "    Returns:  all id masks in single numpy tensor.\n",
    "    '''\n",
    "    #lung_file_path = 'data/nrrd_lung/nrrd_lung/' + id_ + '_lung.nrrd'\n",
    "    heart_file_path  = 'data/nrrd_heart/nrrd_heart/' + id_ + '_heart.nrrd'         # Here path hardcoded\n",
    "    #trachea_file_path = 'data/nrrd_trachea/nrrd_trachea/' + id_ + '_trachea.nrrd'\n",
    "    #lung_tensor = read_nrrd_file(lung_file_path, tensor_shape)\n",
    "    heart_tensor = read_nrrd_file(heart_file_path, tensor_shape)\n",
    "    #trachea_tensor = read_nrrd_file(trachea_file_path, tensor_shape)\n",
    "    \n",
    "        \n",
    "    # now each tensor channel is a mask with a unique label\n",
    "    #full_mask = np.stack([lung_tensor, heart_tensor, trachea_tensor])\n",
    "\n",
    "    # reorient the axes from CHWB to BWHC\n",
    "    heart_tensor = np.moveaxis(heart_tensor,\n",
    "                            [0, 1, 2],\n",
    "                            [2, 1, 0]).astype(np.float32)\n",
    "    \n",
    "\n",
    "    return heart_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ce59820f3ceb6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.257687500Z",
     "start_time": "2024-04-22T22:36:38.008753600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(295, 768, 768)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'ID00015637202177877247924'\n",
    "\n",
    "sample_masks = nrrd_to_numpy(id_, (768, 768))\n",
    "sample_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dffda33cff9dac2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.258189100Z",
     "start_time": "2024-04-22T22:36:38.254831800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nsample_data_gif = ImageToGIF(size=(768, 768),\\n                             xy_text=(250, 15))\\n\\nlabel = 'ID00015637202177877247924'\\n\\n\\nfor i in range(sample_masks.shape[0]):\\n    sample_data_gif.add(sample_masks[i],label=f'{label}_{str(i)}', with_mask=False)\\n \\nsample_data_gif.save(f'{label}.gif', fps=15)\\nshow_gif(f'{label}.gif', format='png')\\n\""
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sample_data_gif = ImageToGIF(size=(768, 768),\n",
    "                             xy_text=(250, 15))\n",
    "\n",
    "label = 'ID00015637202177877247924'\n",
    "\n",
    "\n",
    "for i in range(sample_masks.shape[0]):\n",
    "    sample_data_gif.add(sample_masks[i],label=f'{label}_{str(i)}', with_mask=False)\n",
    " \n",
    "sample_data_gif.save(f'{label}.gif', fps=15)\n",
    "show_gif(f'{label}.gif', format='png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e83299c4b18c7d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.267196Z",
     "start_time": "2024-04-22T22:36:38.259686100Z"
    }
   },
   "outputs": [],
   "source": [
    "label = 'ID00015637202177877247924'\n",
    "\n",
    "sample_path = 'data/train/' + label\n",
    "sample_path_files = sorted(os.listdir(sample_path), key=lambda x: int(x[:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f0ee34b8cad7b9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.272251500Z",
     "start_time": "2024-04-22T22:36:38.265695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nsample_data_gif = ImageToGIF()\\nlabelOUT = label + '_with_masks'\\nfor i in range(sample_masks.shape[0]):\\n    path = os.path.join(sample_path, sample_path_files[i])\\n    image = pdm.dcmread(path).pixel_array\\n    mask = sample_masks[i]\\n    sample_data_gif.add(image, mask, label=f'{labelOUT}_{str(i)}',)\\n \\nsample_data_gif.save(f'{labelOUT}.gif', fps=15)\\nshow_gif(f'{labelOUT}.gif', format='png')\\n\\n\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sample_data_gif = ImageToGIF()\n",
    "labelOUT = label + '_with_masks'\n",
    "for i in range(sample_masks.shape[0]):\n",
    "    path = os.path.join(sample_path, sample_path_files[i])\n",
    "    image = pdm.dcmread(path).pixel_array\n",
    "    mask = sample_masks[i]\n",
    "    sample_data_gif.add(image, mask, label=f'{labelOUT}_{str(i)}',)\n",
    " \n",
    "sample_data_gif.save(f'{labelOUT}.gif', fps=15)\n",
    "show_gif(f'{labelOUT}.gif', format='png')\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb915ab869746504",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.273755900Z",
     "start_time": "2024-04-22T22:36:38.269744900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ntrain_data_paths = pd.read_csv('data/train.csv')\\ntest_data_paths = pd.read_csv('data/test.csv')\\ntrain_data_paths.head()\\n\""
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_data_paths = pd.read_csv('data/train.csv')\n",
    "test_data_paths = pd.read_csv('data/test.csv')\n",
    "train_data_paths.head()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc07c6e3a9203598",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:38.309365600Z",
     "start_time": "2024-04-22T22:36:38.274757600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                     Patient\n0  ID00007637202177411956430\n1  ID00009637202177434476278\n2  ID00010637202177584971671\n3  ID00012637202177665765362\n4  ID00014637202177757139317",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00009637202177434476278</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00010637202177584971671</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00012637202177665765362</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00014637202177757139317</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_ids = os.listdir('data/nrrd_heart/nrrd_heart/')\n",
    "segment_ids = map(lambda x: x.split('_')[0], segment_ids)\n",
    "segment_ids = pd.DataFrame(segment_ids, columns=['Patient'])\n",
    "segment_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcd87c7bfc1522f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:58:20.188909900Z",
     "start_time": "2024-04-22T22:58:20.181105400Z"
    }
   },
   "outputs": [],
   "source": [
    "class HeartDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 imgs_dir: str,\n",
    "                 masks_dir:str,\n",
    "                 df: pd.DataFrame,\n",
    "                 transform = None):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        self.root_imgs_dir = imgs_dir\n",
    "        self.root_masks_dir = masks_dir\n",
    "        self.df = df\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id = self.df.loc[idx, \"Patient\"]\n",
    "        full_image = []\n",
    "        for image_id in sorted(os.listdir(self.root_imgs_dir + id), key=lambda x: int(x[:-4])):\n",
    "            image = pdm.dcmread(self.root_imgs_dir + id + '/' + image_id)\n",
    "            #image.PhotometricInterpretation  = 'YBR_FULL'\n",
    "            image = image.pixel_array\n",
    "            full_image.append(image)\n",
    "            \n",
    "        full_image = np.array(full_image, dtype=np.float32)\n",
    "        mask_shape = full_image.shape[1:]\n",
    "        mask = nrrd_to_numpy(id, mask_shape)\n",
    "        \n",
    "\n",
    "        \n",
    "        if full_image is None or mask is None:\n",
    "            raise FileNotFoundError(f\"Image with id {id} not found.\")\n",
    "        \n",
    "        \n",
    "        if full_image.shape[0] < 200:\n",
    "            full_image = np.pad(full_image, ((0, 100 - full_image.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "            mask = np.pad(mask, ((0, 100 - mask.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "        \n",
    "        if full_image.shape[0] > 200:\n",
    "            full_image = full_image[:100]\n",
    "            mask = mask[:100]\n",
    "\n",
    "        if full_image.shape[1] < 512:\n",
    "            full_image = np.pad(full_image, ((0, 0), (0, 512 - full_image.shape[1]), (0, 0)), mode='constant')\n",
    "            mask = np.pad(mask, ((0, 0), (0, 512 - mask.shape[1]), (0, 0)), mode='constant')\n",
    "        \n",
    "        if full_image.shape[1] > 512:\n",
    "            full_image = full_image[:, :512, :512]\n",
    "            mask = mask[:, :512, :512]\n",
    "        \n",
    "        full_image = self.transform(full_image)\n",
    "        mask = self.transform(mask)\n",
    "            \n",
    "        \n",
    "        return full_image, mask"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 30) (512, 512, 30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m HeartDataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/train/\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/nrrd_heart/nrrd_heart/\u001B[39m\u001B[38;5;124m'\u001B[39m, segment_ids)\n\u001B[1;32m----> 2\u001B[0m item, label \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(item\u001B[38;5;241m.\u001B[39mshape, label\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m dataset\n",
      "Cell \u001B[1;32mIn[32], line 37\u001B[0m, in \u001B[0;36mHeartDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m full_image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage with id \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mid\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 37\u001B[0m augmented \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image\u001B[38;5;241m=\u001B[39mfull_image, mask\u001B[38;5;241m=\u001B[39mmask)\n\u001B[0;32m     38\u001B[0m full_image \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     39\u001B[0m mask \u001B[38;5;241m=\u001B[39m augmented[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "dataset = HeartDataset('data/train/', 'data/nrrd_heart/nrrd_heart/', segment_ids)\n",
    "item, label = dataset.__getitem__(0)\n",
    "\n",
    "print(item.shape, label.shape)\n",
    "\n",
    "del dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:45:38.702443100Z",
     "start_time": "2024-04-22T22:45:38.636568300Z"
    }
   },
   "id": "95647dcc260551f3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34dfe8ce310ad320",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:40:25.789329400Z",
     "start_time": "2024-04-22T22:40:25.786766900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    imgs_dir: str,\n",
    "    masks_dir: str,\n",
    "    batch_size: int = 8,\n",
    "    test_size: float = 0.2,\n",
    "    df: pd.DataFrame = segment_ids,\n",
    "    train_transforms=None,\n",
    "    test_transforms=None,\n",
    "):\n",
    "    '''Returns: dataloader for the model training'''\n",
    "    \n",
    "\n",
    "    train_df, val_df = train_test_split(df, \n",
    "                                          test_size=test_size, \n",
    "                                          random_state=69)\n",
    "    train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}\")\n",
    "    print(f\"Val: {len(val_df)}\")\n",
    "    print(train_df.head())\n",
    "    print(val_df.head())\n",
    "    train_data_set = HeartDataset(imgs_dir, masks_dir, train_df, transform=train_transforms)\n",
    "    train_loader = DataLoader(\n",
    "        train_data_set,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "    \n",
    "    test_data_set = HeartDataset(imgs_dir, masks_dir, val_df, transform=test_transforms)\n",
    "    test_loader = DataLoader(\n",
    "        test_data_set,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 69\n",
      "Val: 18\n",
      "                     Patient\n",
      "0  ID00398637202303897337979\n",
      "1  ID00009637202177434476278\n",
      "2  ID00411637202309374271828\n",
      "3  ID00417637202310901214011\n",
      "4  ID00123637202217151272140\n",
      "                     Patient\n",
      "0  ID00072637202198161894406\n",
      "1  ID00360637202295712204040\n",
      "2  ID00323637202285211956970\n",
      "3  ID00358637202295388077032\n",
      "4  ID00032637202181710233084\n",
      "(240, 768, 768) (240, 768, 768)\n",
      "(64, 512, 512) (64, 512, 512)\n",
      "(278, 512, 512) (278, 512, 512)\n",
      "(233, 512, 512) (233, 512, 512)\n",
      "(355, 512, 512) (355, 512, 512)\n",
      "(33, 512, 512) (33, 512, 512)\n",
      "(302, 512, 512) (302, 512, 512)\n",
      "(32, 512, 512) (32, 512, 512)\n",
      "torch.Size([8, 100, 512, 512]) torch.Size([8, 100, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.transforms.v2 import Compose, Normalize, ToDtype, RandomVerticalFlip\n",
    "\n",
    "train_transforms = Compose([\n",
    "    Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225)),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "test_transforms = Compose([\n",
    "    Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225)),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "train_dataloader, test_dataloader = get_dataloader('data/train/', 'data/nrrd_heart/nrrd_heart/', train_transforms=train_transforms, test_transforms=test_transforms)\n",
    "item, label = next(iter(train_dataloader))\n",
    "print(item.shape, label.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:58:29.368276100Z",
     "start_time": "2024-04-22T22:58:24.511792700Z"
    }
   },
   "id": "53f55bd7b2b16dbc",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "\n",
    "sample_data_gif = ImageToGIF()\n",
    "labelOUT = segment_ids.loc[index, \"Patient\"] + '_with_masks'\n",
    "for i in range(item.shape[0]):\n",
    "    sample_data_gif.add(item[i], label[i], label=f'{labelOUT}_{str(i)}',)\n",
    " \n",
    "print(labelOUT)\n",
    "sample_data_gif.save(f'{labelOUT}.gif', fps=15)\n",
    "show_gif(f'{labelOUT}.gif', format='png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:36:39.009279900Z",
     "start_time": "2024-04-22T22:36:39.009279900Z"
    }
   },
   "id": "c5f2e1bd0c4bb612",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def dice_coef_metric(probabilities: torch.Tensor,\n",
    "                     truth: torch.Tensor,\n",
    "                     treshold: float = 0.5,\n",
    "                     eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Dice score for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: dice score aka f1.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = 2.0 * (truth_ * prediction).sum()\n",
    "        union = truth_.sum() + prediction.sum()\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def jaccard_coef_metric(probabilities: torch.Tensor,\n",
    "               truth: torch.Tensor,\n",
    "               treshold: float = 0.5,\n",
    "               eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Jaccard index for data batch.\n",
    "    Params:\n",
    "        probobilities: model outputs after activation function.\n",
    "        truth: truth values.\n",
    "        threshold: threshold for probabilities.\n",
    "        eps: additive to refine the estimate.\n",
    "        Returns: jaccard score aka iou.\"\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    num = probabilities.shape[0]\n",
    "    predictions = (probabilities >= treshold).float()\n",
    "    assert(predictions.shape == truth.shape)\n",
    "\n",
    "    for i in range(num):\n",
    "        prediction = predictions[i]\n",
    "        truth_ = truth[i]\n",
    "        intersection = (prediction * truth_).sum()\n",
    "        union = (prediction.sum() + truth_.sum()) - intersection + eps\n",
    "        if truth_.sum() == 0 and prediction.sum() == 0:\n",
    "            scores.append(1.0)\n",
    "        else:\n",
    "            scores.append((intersection + eps) / union)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "class Meter:\n",
    "    '''factory for storing and updating iou and dice scores.'''\n",
    "    def __init__(self, treshold: float = 0.5):\n",
    "        self.threshold: float = treshold\n",
    "        self.dice_scores: list = []\n",
    "        self.iou_scores: list = []\n",
    "    \n",
    "    def update(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes: logits from output model and targets,\n",
    "        calculates dice and iou scores, and stores them in lists.\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(logits)\n",
    "        dice = dice_coef_metric(probs, targets, self.threshold)\n",
    "        iou = jaccard_coef_metric(probs, targets, self.threshold)\n",
    "        \n",
    "        self.dice_scores.append(dice)\n",
    "        self.iou_scores.append(iou)\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"\n",
    "        Returns: the average of the accumulated dice and iou scores.\n",
    "        \"\"\"\n",
    "        dice = np.mean(self.dice_scores)\n",
    "        iou = np.mean(self.iou_scores)\n",
    "        return dice, iou\n",
    "    \n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Calculate dice loss.\"\"\"\n",
    "    def __init__(self, eps: float = 1e-9):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,\n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        num = targets.size(0)\n",
    "        probability = torch.sigmoid(logits)\n",
    "        probability = probability.view(num, -1)\n",
    "        targets = targets.view(num, -1)\n",
    "        assert(probability.shape == targets.shape)\n",
    "        \n",
    "        intersection = 2.0 * (probability * targets).sum()\n",
    "        union = probability.sum() + targets.sum()\n",
    "        dice_score = (intersection + self.eps) / union\n",
    "        #print(\"intersection\", intersection, union, dice_score)\n",
    "        return 1.0 - dice_score\n",
    "        \n",
    "        \n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"Compute objective loss: BCE loss + DICE loss.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        \n",
    "    def forward(self, \n",
    "                logits: torch.Tensor,\n",
    "                targets: torch.Tensor) -> torch.Tensor:\n",
    "        assert(logits.shape == targets.shape)\n",
    "        dice_loss = self.dice(logits, targets)\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "        \n",
    "        return bce_loss + dice_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:01:43.530377500Z",
     "start_time": "2024-04-22T23:01:43.523310700Z"
    }
   },
   "id": "ba7a8cd580262bf1",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Unet('efficientnet-b2', encoder_weights=\"imagenet\", classes=3, activation=None)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b0dcd47f5e26d02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
